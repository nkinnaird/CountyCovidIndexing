{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_census_info = pd.read_pickle(\"../Data/county_census_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Autauga County', 'Alabama')\n"
     ]
    }
   ],
   "source": [
    "indices = county_census_info.index\n",
    "print(indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(value_string_reduced):\n",
    "  try:\n",
    "    float(value_string_reduced)\n",
    "    return float(value_string_reduced)\n",
    "  except ValueError:\n",
    "    return math.nan\n",
    "\n",
    "def grabInitialMetric(soup, input_id):\n",
    "    this_div = soup.find('div', id=input_id)\n",
    "    this_span = this_div.find('span', id='initialMetric')\n",
    "#     return isfloat(this_span.text)\n",
    "    return isfloat(this_span.text.split(\" \")[0])\n",
    "\n",
    "def grabPerMetric(soup, input_id):\n",
    "    this_div = soup.find('div', id=input_id)\n",
    "    sub_div = this_div.find('div', class_='rates')\n",
    "    per_text = sub_div.text\n",
    "    line_of_interest = per_text.split(\"\\n\")[1].split(\" \")    \n",
    "    while('' in line_of_interest): \n",
    "        line_of_interest.remove('')\n",
    "    return isfloat(line_of_interest[0].replace(\"(\",''))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabCovidData(soup):\n",
    "\n",
    "    county_dict = {}\n",
    "\n",
    "#     top_soup = soup\n",
    "\n",
    "#     time.sleep(1)\n",
    "\n",
    "    svi_span = soup.find('span', id='svi_rank')\n",
    "    svi_value = isfloat(svi_span.text)\n",
    "    county_dict['SVI'] = svi_value\n",
    "    \n",
    "#     time.sleep(1)\n",
    "    \n",
    "    ccvi_span = soup.find('span', id='ccvi_score')\n",
    "    ccvi_value = isfloat(ccvi_span.text)\n",
    "    county_dict['CCVI'] = ccvi_value\n",
    "    \n",
    "#     cases_div = soup.find('div', id='cases-timeseries-wrapper')\n",
    "#     cases_span = cases_div.find('span', id='initialMetric')\n",
    "#     county_dict['Cases'] = isfloat(cases_span.text)\n",
    "    \n",
    "    county_dict['Cases'] = grabInitialMetric(soup, 'cases-timeseries-wrapper')\n",
    "    county_dict['Cases per 100k'] = grabPerMetric(soup, 'cases-timeseries-wrapper')\n",
    "\n",
    "    county_dict['Deaths'] = grabInitialMetric(soup, 'deaths-timeseries-wrapper')\n",
    "    county_dict['Deaths per 100k'] = grabPerMetric(soup, 'deaths-timeseries-wrapper')\n",
    "\n",
    "    county_dict['Percent Positivity'] = grabInitialMetric(soup, 'positivity-timeseries-wrapper')\n",
    "    \n",
    "    county_dict['Testing Volume'] = grabInitialMetric(soup, 'testing-timeseries-wrapper')\n",
    "    county_dict['Testing Volume per 100k'] = grabPerMetric(soup, 'testing-timeseries-wrapper')\n",
    "\n",
    "    county_dict['New Hospital Admissions'] = grabInitialMetric(soup, 'hospital-admissions-timeseries-wrapper')\n",
    "    county_dict['New Hospital Admissions per 100 beds'] = grabPerMetric(soup, 'hospital-admissions-timeseries-wrapper')\n",
    "\n",
    "    county_dict['Percent Beds Used (Covid)'] = grabInitialMetric(soup, 'hospital-percent-beds-timeseries-wrapper')\n",
    "    \n",
    "    \n",
    "        \n",
    "#     cases_rates_div = cases_div.find('div', class_='rates')\n",
    "#     cases_per_100k_text = cases_rates_div.text\n",
    "#     line_of_interest = cases_per_100k_text.split(\"\\n\")[1].split(\" \")    \n",
    "#     while('' in line_of_interest): \n",
    "#         line_of_interest.remove('')\n",
    "#     county_dict['Cases per 100k'] = isfloat(line_of_interest[0].replace(\"(\",''))\n",
    "\n",
    "    \n",
    "    \n",
    "#     print(cases_per_100k_text.split(\"\\n\"))\n",
    "#     print(cases_per_100k_text.split(\"\\n\")[0])\n",
    "#     print(cases_per_100k_text.split(\"\\n\")[0].replace(\"(\",''))\n",
    "    \n",
    "#     i = 0\n",
    "#     for tbody in table_div.find_all('tbody'):\n",
    "#         tbody_text = tbody.text\n",
    "\n",
    "#         i+=1\n",
    "#         if(i==1): continue\n",
    "            \n",
    "#         # read table in which returns a lot of text, then parse the text and drop various things to get the data\n",
    "                \n",
    "#         list_of_text = tbody_text.split(\"\\n\")\n",
    "        \n",
    "#         while('' in list_of_text): \n",
    "#             list_of_text.remove('')\n",
    "#         while('\\ue840\\ue83f' in list_of_text):             \n",
    "#             list_of_text.remove('\\ue840\\ue83f')\n",
    "            \n",
    "        \n",
    "#         list_of_text.pop(0)    \n",
    "        \n",
    "#         # grab data titles and values and zip them together\n",
    "        \n",
    "#         for label, value in zip(list_of_text[0::2], list_of_text[1::2]):\n",
    "#             value_number = removeStringCharacters(value)\n",
    "#             county_dict[label] = value_number\n",
    "    \n",
    "#     return county_dict\n",
    "\n",
    "    print(county_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SVI': 0.38, 'CCVI': 0.11, 'Cases': 4117.0, 'Cases per 100k': 323.17, 'Deaths': 27.0, 'Deaths per 100k': 2.12, 'Percent Positivity': 13.11, 'Testing Volume': 29397.0, 'Testing Volume per 100k': 2307.54, 'New Hospital Admissions': 438.0, 'New Hospital Admissions per 100 beds': 18.63, 'Percent Beds Used (Covid)': 18.93}\n"
     ]
    }
   ],
   "source": [
    "# open the cdc website and choose the state and county from the drop down menu\n",
    "\n",
    "cdc_county_website = \"https://covid.cdc.gov/covid-data-tracker/#county-view\"\n",
    "\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(cdc_county_website)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "select = Select(driver.find_element_by_id('list_select_state'))\n",
    "select.select_by_visible_text('Texas')\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "select = Select(driver.find_element_by_id('list_select_county'))\n",
    "select.select_by_visible_text('Travis')\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "# scrape data from the page\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "grabCovidData(soup)\n",
    "\n",
    "\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
